# llm_evaluator/metrics/base.py

from abc import ABC, abstractmethod

class BaseMetric(ABC):
    """
    Abstract Base Class for a metric evaluation.
    """

    @abstractmethod
    def compute(self, generated_text: str, context: dict) -> tuple:
        """
        Compute the metric score based on the generated text and context.
        
        :param generated_text: Text generated by the primary LLM.
        :param context: Additional context for evaluation (e.g., retrieved documents).
        :return: A tuple containing the metric name and its computed score.
        """
        pass
